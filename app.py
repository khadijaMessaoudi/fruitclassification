import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.models import load_model
import streamlit as st
import numpy as np

# Load the trained model and compile it
model = load_model('C:\\Users\\MSI\\Desktop\\test\\vegetable_model.h5')
model.compile(optimizer="adam", loss="categorical_crossentropy", metrics=["accuracy"])  # Ensure model is compiled

# Define category labels and emojis
data_cat = [
    ['apple', 'ğŸ'], ['banana', 'ğŸŒ'], ['beetroot', 'ğŸŒ±'], ['bell pepper', ' '],
    ['cabbage', 'ğŸ¥¬'], ['capsicum', ' '], ['carrot', 'ğŸ¥•'], ['cauliflower', 'ğŸŒ¸'],
    ['chilli pepper', 'ğŸŒ¶ï¸'], ['corn', 'ğŸŒ½'], ['cucumber', 'ğŸ¥’'], ['eggplant', 'ğŸ†'],
    ['garlic', 'ğŸ§„'], ['ginger', ' '], ['grapes', 'ğŸ‡'], ['jalepeno', 'ğŸŒ¶ï¸'],
    ['kiwi', 'ğŸ¥'], ['lemon', 'ğŸ‹'], ['lettuce', 'ğŸ¥¬'], ['mango', 'ğŸ¥­'],
    ['onion', 'ğŸ§…'], ['orange', 'ğŸŠ'], ['paprika', 'ğŸŒ¶ï¸'], ['pear', 'ğŸ'],
    ['peas', 'ğŸŸ¢'], ['pineapple', 'ğŸ'], ['pomegranate', ' '], ['potato', 'ğŸ¥”'],
    ['raddish', 'ğŸŒ±'], ['soy beans', ' '], ['spinach', 'ğŸ¥¬'], ['sweetcorn', 'ğŸŒ½'],
    ['sweetpotato', 'ğŸ '], ['tomato', 'ğŸ…'], ['turnip', 'ğŸŒ±'], ['watermelon', 'ğŸ‰']
]

img_height = 224
img_width = 224

# Streamlit UI Setup
st.set_page_config(page_title="Fruit & Vegetable Classifier", layout="centered")

st.sidebar.title("About the Model")
st.sidebar.markdown("""
    - **Type**: Image Classification  
    - **Model**: Convolutional Neural Network (CNN)  
    - **Framework**: TensorFlow/Keras  
    - **Classes**: 36 Categories  
""")

st.title("ğŸŒŸ Fruit & Vegetable Classifier ğŸŒŸ")
st.write("Upload an image of a fruit or vegetable, and this app will classify it for you!")

# File uploader
uploaded_file = st.file_uploader("Choose an image", type=["jpg", "jpeg", "png"])

if uploaded_file:
    try:
        # Load and preprocess the image
        image_load = tf.keras.utils.load_img(uploaded_file, target_size=(img_height, img_width))
        img_arr = tf.keras.utils.img_to_array(image_load)  # Convert image to array
        img_arr = img_arr / 255.0  # Normalize pixel values
        img_bat = np.expand_dims(img_arr, axis=0)  # Add batch dimension

        # Model prediction
        predict = model.predict(img_bat)
        predicted_index = np.argmax(predict)  # Get class index
        predicted_class, emoji = data_cat[predicted_index]  # Get class name and emoji
        confidence = np.max(predict) * 100  # Get confidence score

        # Display results
        st.image(uploaded_file, width=250, caption="Uploaded Image")
        st.markdown(f"### Predicted Category: **{predicted_class}** {emoji}")
        st.progress(int(confidence))
        st.markdown(f"### ğŸ¯ Confidence: **{confidence:.2f}%**")

    except Exception as e:
        st.error(f"An error occurred: {str(e)}")
else:
    st.info("ğŸ‘† Upload an image file to get started!")
